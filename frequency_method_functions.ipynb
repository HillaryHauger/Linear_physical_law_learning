{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac309a9f",
   "metadata": {},
   "source": [
    "# Implement frequency method functions\n",
    "Implement following functions:\n",
    "1. Calculate the derivative via extension and fftn, then use Linear Regression with $L_1$ norm\n",
    "2. Use curve fitting via pytorch for $\\hat{u}(t,\\xi) = \\hat{u}(0,\\xi)exp(t\\sum_j(a_ji^{|j|}\\xi^j))$ to calculate coefficients.\n",
    "   Note for $u_{tt} = \\sum_{j}a_j u_j$ the general solution for $\\hat{u}$ is  $\\hat{u}(t,\\xi) = C_1(\\xi)exp(t\\sqrt{\\lambda}) + C_2(\\xi)exp(-t\\sqrt{\\lambda})$ for $\\lambda = \\sum_j(a_ji^{|j|}\\xi^j), C_1 + C_2 = \\hat{u}(0,\\xi)$\n",
    "3. Use PDE-Find Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e988e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import pysindy as ps\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.fft import fftn, ifftn, fftfreq,fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60578b4",
   "metadata": {},
   "source": [
    "### Functions for calculating derivative and extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc35d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the spectral derivative for n-dimensional input and order\n",
    "# Takes ax and d as liste e.g. ax = [0], d =[0.1]\n",
    "def calc_deriv_fftn(f,ax,d):\n",
    "    if isinstance(ax, list) == False or isinstance(ax, list) == False:\n",
    "        print(\"ax and d are only valid as a list\")\n",
    "        print(\"Exit calc_deriv_fftn\")\n",
    "        return None\n",
    "    order = len(ax)\n",
    "    fftf = fftn(f)\n",
    "    frequencies = []\n",
    "    # Calculate frequencies\n",
    "    for i in range(order):\n",
    "        frequencies.append(fftfreq(f.shape[ax[i]],d[i]))\n",
    "\n",
    "    #Expand frequencies so we can  multiply\n",
    "    for j in range(order):\n",
    "        liste = list(range(f.ndim)) \n",
    "        liste.remove(ax[j])\n",
    "        for i in liste:\n",
    "            frequencies[j] = np.expand_dims(frequencies[j],axis=i)\n",
    "            frequencies[j] = np.repeat(frequencies[j],f.shape[i],axis=i)\n",
    "        fftf *=2*np.pi*1j*frequencies[j]\n",
    "    return ifftn(fftf).real\n",
    "\n",
    "\n",
    "def create_data_2d(T_start, T_end, L_x, N_t, N_x):\n",
    "    t = np.linspace(T_start, T_end, num=N_t)\n",
    "    x = np.linspace(-L_x/2.0, L_x/2.0, num=N_x)\n",
    "    T,X = np.meshgrid(t,x)\n",
    "    return T,X,t,x\n",
    "\n",
    "def create_data_3d(T_start, T_end, L_x,L_y, N_t, N_x,N_y):\n",
    "    t = np.linspace(T_start, T_end, num=N_t)\n",
    "    x = np.linspace(-L_x/2.0, L_x/2.0, num=N_x)\n",
    "    y = np.linspace(-L_y/2.0, L_y/2.0, num=N_y)\n",
    "    T,X,Y = np.meshgrid(t,x,y)\n",
    "    return T,X,Y,t,x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdc91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes f and x, creates more datapoints s.t. f \n",
    "# can be extended to a periodic function with value 0 at end and beginning\n",
    "# return newf, newx, newn, only works for one_dim function\n",
    "def flattenandextendfunc_1d(f,x):\n",
    "    # error handling\n",
    "    if f.size!=x.size:\n",
    "        print(\"Error: f and x do not have same size: f.size=\"\n",
    "              +str(f.size)+\",x.size=\"+str(x.size))\n",
    "        print(\"Exit flattenandextendfu\")\n",
    "        return None\n",
    "    # Get necessary data to extend f\n",
    "    dx = x[1]-x[0]\n",
    "    A=x[0]\n",
    "    B=x[x.size-1]\n",
    "    n=max(int(x.size/10),20) \n",
    "    # Create new data\n",
    "    newx=np.arange(A-n*dx,B +n*dx,dx)\n",
    "    newf=np.empty(newx.size, dtype=float)\n",
    "    oldf=newf.copy()\n",
    "    # Get slope at beg and end\n",
    "    slope_start = (f[1]-f[0])/dx\n",
    "    slope_end = (f[f.size-1]-f[f.size-2])/dx\n",
    "    # Extend oldf\n",
    "    oldf[n:n+f.size]=f\n",
    "    oldf[n+f.size:]=slope_end*dx*np.arange(1, oldf[n+f.size:].size+1)+f[f.size-1]\n",
    "    oldf[:n]=f[0]-slope_start*dx*np.arange(1, oldf[:n].size+1)[::-1] #[::-1] means reverse array\n",
    "    # Create newf: in the middle equal to f, continuous extension such that \n",
    "    # start and endpoint are equal to one\n",
    "    a=30\n",
    "    half = A+(B-A)/2\n",
    "    newf[newx<=half]=1.0/(1.0 + np.exp(-a*(newx[newx<=half]-(A-n/2*dx))))\n",
    "    newf[newx>half]=-1.0/(1.0 + np.exp(-a*(newx[newx>half]-(B+n/2*dx))))+1.0\n",
    "    newf = newf*oldf\n",
    "    return newf,newx,n\n",
    "\n",
    "def getnewsize(x):\n",
    "    dx = x[1]-x[0]\n",
    "    A=x[0]\n",
    "    B=x[x.size-1]\n",
    "    n=max(int(x.size/10),20) \n",
    "    newx=np.arange(A-n*dx,B +n*dx,dx)\n",
    "    return newx.size\n",
    "\n",
    "# Extends multidimensional function\n",
    "def flattenandextendfunc_nd(f,inp):\n",
    "    dim = f.ndim # get dimension\n",
    "    newsize=[getnewsize(myinp) for myinp in inp]\n",
    "    n=[]\n",
    "    newinp=inp.copy()\n",
    "    temp=[]\n",
    "    liste = list(range(dim))\n",
    "    # Iterate through axis: extend function for selected axis\n",
    "    for axis in liste:\n",
    "        liste_drop = liste.copy()\n",
    "        liste_drop.remove(axis)\n",
    "        \n",
    "        # Calculate new shape\n",
    "        shape = list(f.shape)\n",
    "        shape[axis]=newsize[axis]\n",
    "        shape = tuple(shape)\n",
    "        temp = np.zeros(shape) #Create array with new extended shape\n",
    "\n",
    "        start = np.zeros(dim, dtype=int) #for slicing\n",
    "        end = np.zeros(dim, dtype=int)+f.shape[axis] # for slicing\n",
    "        newend = np.zeros(dim, dtype=int)+newsize[axis] #for slicing new array\n",
    "\n",
    "        # Select and save ranges in rangelist for iterating\n",
    "        rangelist =[]\n",
    "        for otheraxis in liste_drop:\n",
    "            rangelist.append(range(f.shape[otheraxis]))  \n",
    "\n",
    "        #Extend function for axis\n",
    "        for J in itertools.product(*rangelist):\n",
    "            i=0\n",
    "            #Calculate slice\n",
    "            for otheraxis in liste_drop:\n",
    "                start[otheraxis] = J[i]\n",
    "                end[otheraxis]=J[i]+1\n",
    "                newend[otheraxis] = end[otheraxis]\n",
    "                i+=1\n",
    "            myslice =tuple(slice(*indexes) for indexes in zip(start, end))\n",
    "            newslice =tuple(slice(*indexes) for indexes in zip(start, newend))\n",
    "\n",
    "            #Extend one dimensional version\n",
    "            col, newinp_axis, n_axis =flattenandextendfunc_1d(f[myslice].ravel(),newinp[axis])\n",
    "            temp[newslice] = col.reshape(temp[newslice].shape)\n",
    "\n",
    "        f = temp #Set f equal to temp    \n",
    "        # Save new Input and new numbers f data\n",
    "        newinp[axis]=newinp_axis\n",
    "        n.append(n_axis)\n",
    "\n",
    "    return f,newinp,n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95316042",
   "metadata": {},
   "source": [
    "### Functions for $L_1$ Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997fe2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for L_1 regression\n",
    "\n",
    "def check_orderinput_matches_orderaxis(inp,u):\n",
    "    for i in range(u.ndim):\n",
    "        if u.shape[i]!=inp[i].size:\n",
    "            print(\"Axis \"+str(i)+\"  with shape \"+str(u.shape[i])+\n",
    "                  \" does not match size of inp[\"+str(i)+\"] \"+str(inp[i].size))\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "def fit(X, params):\n",
    "    return X.dot(params)\n",
    "\n",
    "def cost_function(params, inp, y):\n",
    "    return np.sum(np.abs(y - fit(inp, params)))\n",
    "\n",
    "def frequency_method_regr(u,inp,order=1,time_deriv = 1):\n",
    "    #Error prevention\n",
    "    if check_orderinput_matches_orderaxis(inp,u)==False:\n",
    "        return None #prevent errors in flattenandextenfunc\n",
    "    \n",
    "    newu,newinp,n = flattenandextendfunc_nd(u,inp)\n",
    "\n",
    "    inp_regr = []\n",
    "    inp_regr.append(u.ravel())\n",
    "    d = [myinp[1]-myinp[0] for myinp in inp] #saves distance\n",
    "    #Define slice to get right values from extension\n",
    "    start = n\n",
    "    end = [sum(x) for x in zip(n, list(u.shape))] #end = n0+u.shape[0],n1+u.shape[1],...\n",
    "    myslice =tuple(slice(*indexes) for indexes in zip(start, end))\n",
    "    \n",
    "    #Calculate derivative for order and dimension\n",
    "    for j in range(1,order+1):\n",
    "            liste = list(range(0,u.ndim))\n",
    "            liste.remove(1) #remove axis for t\n",
    "            for subset in itertools.combinations_with_replacement(liste,j):\n",
    "                axis = list(subset)\n",
    "                dist = [d[ax] for ax in axis]\n",
    "                x_ai = calc_deriv_fftn(newu,axis,dist)\n",
    "                inp_regr.append(x_ai[myslice].ravel())\n",
    "\n",
    "    #Define In- and Output for regression\n",
    "    #Distinguish between time_deriv =1 <-> u_t = ... and time_deriv=2 <-> u_tt = ...\n",
    "    if time_deriv == 1:\n",
    "        y = calc_deriv_fftn(newu,[1],[d[1]])\n",
    "    elif time_deriv ==2:\n",
    "        y = calc_deriv_fftn(newu,[1,1],[d[1],d[1]])\n",
    "    \n",
    "    #If data is real:\n",
    "    y=y[myslice].ravel()\n",
    "    input_regr = np.stack(inp_regr,axis=1)\n",
    "    #Use values from OLS regression as initial data for minimization\n",
    "    model = sm.OLS(np.real(y),np.real(input_regr))\n",
    "    results = model.fit()\n",
    "    output = minimize(cost_function, (results.params), args=(np.real(input_regr), np.real(y)))\n",
    "\n",
    "    return output.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3169a77",
   "metadata": {},
   "source": [
    "### Functions for Curvefit\n",
    "Important: Input u must be given with the right periodicity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fbfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multidim input\n",
    "def get_boundarypoints_time(func,t_0,t_1,N_t):\n",
    "    #get V(x)=func(x,t_0), V1(x)=func(x,t_1)\n",
    "    start = np.zeros(func.ndim, dtype=int) #for slicing\n",
    "    end = start+func.size # for slicing\n",
    "    start[1],end[1]=[t_0,t_0+1] #select t=t_0\n",
    "    V = func[tuple(slice(*indexes) for indexes in zip(start, end))]\n",
    "    V = np.repeat(V,N_t,axis=1)  #expand V for multiplication\n",
    "    V = torch.from_numpy(V.ravel()).type(torch.complex128)\n",
    "    start[1],end[1]=[t_1,t_1+1] #select t=t_1\n",
    "    V1 = func[tuple(slice(*indexes) for indexes in zip(start, end))]\n",
    "    V1 = np.repeat(V1,N_t,axis=1)  #expand V for multiplication\n",
    "    V1 = torch.from_numpy(V1.ravel()).type(torch.complex128)\n",
    "    return V,V1\n",
    "\n",
    "def get_frequencies(d,N,ax,u):\n",
    "    dimx = len(N)\n",
    "    frequencies=[] \n",
    "    # Calculate frequencies\n",
    "    for i in range(dimx):\n",
    "        frequencies.append(fftfreq(u.shape[ax[i]],d[i]))\n",
    "        \n",
    "    #Expand frequencies so we can  multiply\n",
    "    for j in range(dimx):\n",
    "        liste = list(range(u.ndim))\n",
    "        liste.remove(ax[j])\n",
    "        for i in liste:\n",
    "            frequencies[j] = np.expand_dims(frequencies[j],axis=i)\n",
    "            frequencies[j] = np.repeat(frequencies[j],u.shape[i],axis=i) \n",
    "        frequencies[j]=torch.from_numpy(frequencies[j].ravel()).type(torch.complex128)\n",
    "    return frequencies\n",
    "\n",
    "def func(para,u_dft,N_t,T,order,dimx,frequencies,time_deriv=1):\n",
    "    #Calcuclate u_dft(t=0), u_dft(t=t1)\n",
    "    V,V1=get_boundarypoints_time(u_dft,0,N_t-1,N_t)\n",
    "    \n",
    "    #Calculate tempsum = \\sum_a \\xi^a * i^|a| * t\n",
    "    temp_sum = (para[0][0]*torch.ones(T.shape)).type(torch.complex128) # t will be mutiplied later\n",
    "    for j in range(1,order+1):\n",
    "            deriv_num=0\n",
    "            #subset element in combination of derivatives e.g. [0,0],[0,1],[1,1], 0=x,1=y\n",
    "            for subset in itertools.combinations_with_replacement(range(0,dimx),j):\n",
    "                temp_prod=1.0\n",
    "                for freq_num in range(len(subset)):\n",
    "                    temp_prod*= 1j*2*np.pi*frequencies[subset[freq_num]]\n",
    "                temp_prod*=para[j][deriv_num]\n",
    "                temp_sum+=temp_prod \n",
    "                deriv_num+=1\n",
    "    shift = torch.tensor([700],dtype=torch.complex128) #to prevent overflow\n",
    "    result= torch.exp(shift)*V*torch.exp(T*temp_sum-shift)\n",
    "    #Note we add 1e-14 because gradient of sqrt not well defined at zero\n",
    "    if time_deriv == 2:\n",
    "        #a=V-b, b=(V1-V exp(sqrt(tempsum)t)/( exp(-t sqrt(tempsum))-exp(t sqrt(tempsum)) )\n",
    "        a=torch.zeros(T.shape,dtype=torch.complex128)\n",
    "        b=torch.zeros(T.shape,dtype=torch.complex128)\n",
    "        t0=T[0:1]\n",
    "        t1 = T[N_t-1:N_t]\n",
    "        temp_divide=torch.exp(-t1*torch.sqrt(temp_sum+1e-14)) - torch.exp(t1*torch.sqrt(temp_sum+1e-14))\n",
    "        mask =  [temp_divide!=0]\n",
    "        b[mask]=(V1[mask]-V[mask]*torch.exp(t1*torch.sqrt(temp_sum[mask])))/temp_divide[mask]\n",
    "        a = V-b\n",
    "        result= a*torch.exp(T*torch.sqrt(temp_sum+1e-14)) + b*torch.exp(-T*torch.sqrt(temp_sum+1e-14))\n",
    "    return result\n",
    "    \n",
    "\n",
    "def frequency_method_curvefit(u,T,listofXinput,ax=[0],order=1,epochs=2000, learning_rate=0.01\n",
    "                                , print_loss=False, time_deriv=1):\n",
    "    dtype = torch.float64\n",
    "    dimx = len(listofXinput)\n",
    "    d=[] #saves distanc for Xinputs\n",
    "    N=[] #saves amount of Xinputs\n",
    "    for inp in listofXinput:\n",
    "        d.append(inp[1]-inp[0])\n",
    "        N.append(inp.size)\n",
    "    N_t = T.shape[1]\n",
    "    u_dft=fftn(u,axes=ax)\n",
    "    \n",
    "    frequencies = get_frequencies(d,N,ax,u)\n",
    "    \n",
    "    # Set x and y\n",
    "    T = torch.from_numpy(T.ravel()).type(torch.complex128)\n",
    "    y = torch.from_numpy(u_dft.ravel()).type(torch.complex128)\n",
    "\n",
    "    # Initialise Parameter\n",
    "    para=torch.nn.ParameterList([torch.nn.Parameter(\n",
    "        torch.rand( int(scipy.special.binom(dimx+j-1,j)), dtype=dtype, requires_grad=True))\n",
    "                             for j in range(order+1)])\n",
    "    #not right right nowters\n",
    "    optimiser = torch.optim.Adam(para, lr = learning_rate)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, patience = 10)\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    lossarray = np.array([])\n",
    "    torch.autograd.set_detect_anomaly(True)#gives error if grad returns NaN\n",
    "        \n",
    "    for t in range(epochs):\n",
    "        #Forward Pass\n",
    "        y_pred = func(para,u_dft,N_t,T,order,dimx,frequencies,time_deriv)  \n",
    "        #Error Prevetion\n",
    "        if torch.isinf(y_pred).any():\n",
    "            print(\"Error: inf values in y_pred caused by torch.exp\")\n",
    "            print(\"Epoch: \"+str(t))\n",
    "            return None\n",
    "        if torch.isnan(y_pred).any():\n",
    "            print(\"Error: NaN values in y_pred\")\n",
    "            print(\"Epoch: \"+str(t))\n",
    "            return None\n",
    "        # Compute and save loss\n",
    "        loss = loss_func(y_pred,y)\n",
    "        lossarray= np.append(lossarray,loss.item())\n",
    "        #Print loss\n",
    "        if (t%int(epochs/5) == (int(epochs/5)-1)) & print_loss == True:\n",
    "            print(t, loss.item())\n",
    "            print([para[i] for i in range(len(para))])\n",
    "\n",
    "        # Use optimiser and autograd to update weights\n",
    "        optimiser.zero_grad()     \n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    if print_loss ==True:\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(lossarray)\n",
    "        #plt.yscale('log')\n",
    "        plt.show()\n",
    "    \n",
    "    return [para[i] for i in range(len(para))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e7e59",
   "metadata": {},
   "source": [
    "## PDE-Find\n",
    "see more on https://github.com/dynamicslab/pysindy\n",
    "and https://www.science.org/doi/10.1126/sciadv.1602614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d559cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_find(u,t,x,order,print_model=True):\n",
    "    dt = t[1]-t[0]\n",
    "    pde_lib = ps.PDELibrary(\n",
    "        derivative_order=order,\n",
    "        spatial_grid=x,\n",
    "    )\n",
    "\n",
    "    u_sindy = u.reshape(len(x), len(t), 1) # u in shape (len(x),len(t))\n",
    "    optimizer = ps.STLSQ(threshold=0.0)\n",
    "    model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer,feature_names=[\"u\"])\n",
    "    model.fit(u_sindy, t=dt)\n",
    "    if print_model==True:\n",
    "        model.print()\n",
    "    return model.coefficients()\n",
    "    \n",
    "def pde_find_sec_timederiv(u,t,x,order,print_model=True):\n",
    "    dt = t[1]-t[0]\n",
    "    pde_lib = ps.PDELibrary(\n",
    "        derivative_order=order,\n",
    "        spatial_grid=x,\n",
    "    )\n",
    "    \n",
    "    utt = ps.FiniteDifference(d=2, axis=1,drop_endpoints=False)._differentiate(u, dt) \n",
    "    u_sindy = u.reshape(len(x), len(t), 1) # u in shape (len(x),len(t))\n",
    "    utt = utt.reshape(len(x),len(t),1) # u_tt in shape (len(x),len(t))\n",
    "    optimizer = ps.STLSQ(threshold=0.0)\n",
    "    model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer,feature_names=[\"u\"])\n",
    "    model.fit(u_sindy, t=dt, x_dot = utt)\n",
    "    if print_model==True:\n",
    "        model.print()\n",
    "    return model.coefficients()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
